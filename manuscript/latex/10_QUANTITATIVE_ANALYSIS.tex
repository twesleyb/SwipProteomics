% QUANTIFICATION AND STATISTICAL ANALYSIS

Experimental conditions, number of replicates, and statistical tests used are
stated in each figure legend. Each experiment was replicated at least three
times (or on at least 3 separate animals) to assure rigor and reproducibility.
Both male and female age-matched mice were used for all experiments, with data
pooled from both sexes. Data compilation and statistical analyses for all
non-proteomic data were performed using GraphPad Prism (version 8, GraphPad
Software, CA), using a significance level of alpha=0.05. Prism provides exact p
values unless p<0.0001. All data are reported as mean ± SEM. Each data set was
tested for normal distribution using a D'Agostino-Person normality test to
determine whether parametric (unpaired Student's t-test, one-way ANOVA, two-way
ANOVA) or non-parametric (Mann-Whitney, Kruskal-Wallis) tests should be used.
Parametric assumptions were confirmed with the Shapiro-Wilk test (normality) and
Levine's test (error variance homogeneity) for ANOVA with repeated measures
testing. The analysis of iBioID and TMT proteomics data are described below. All
proteomic data and analysis scripts are available online (see Resource
Availability).

\subsection{Imaris 3D reconstruction}

For EEA1+ and CathepsinD+ puncta analyses, coverslips were imaged on a Zeiss LSM
710 confocal microscope. Images were sampled at a resolution of 1024 x 1024
pixels with a dwell time of 0.45µsec using a 63x/1.4 oil immersion objective, a
2.0 times digital zoom, and a z-step size of 0.37 µm. Images were saved as
“.lsm” formatted files, and quantification was performed on a POGO Velocity
workstation in the Duke Light Microscopy Core Facility using Imaris 9.2.0
software (Bitplane, South Windsor, CT). For analyses, we first used the
“surface” tool to make a solid fill surface of the MAP2-stained neuronal soma
and dendrites, with the background subtraction option enabled. We selected a
threshold that demarcated the neuron structure accurately while excluding
background. For EEA1 puncta analyses, a 600 x 800 µm selection box was placed
around the soma in each image and surfaces were created for EEA1 puncta within
the selection box. Similarly, for CathepsinD puncta analyses, a 600 x 600 µm
selection box was placed around the soma(s) in each image for surface creation.

The same threshold settings were used across all images, and individual surface
data from each soma were exported for aggregate analyses. The experimenter was
blinded to sample conditions for both image acquisition and analysis.

\subsection{Cleaved Caspase-3 Image Analysis}

Z-stack images were acquired on a Zeiss 710 LSM confocal microscope. Images were
sampled at a resolution of 1024 x 1024 pixels with a dwell time of 1.58µsec,
using a 63x/1.4 oil immersion objective (for cortex, striatum, and hippocampus)
or 20x/0.8 dry objective (cerebellum), a 1.0 times digital zoom, and a z-step
size of 0.67 µm. Images were saved as “.lsm” formatted files, and then converted
into maximum intensity projections (MIP) using Zen 2.3 SP1 software.

Quantification of CC3 colocalization with DAPI was performed on the MIPs using
the Particle Analyzer function in FIJI ImageJ software. The experimenter was
blind to sample conditions for both image acquisition and analysis.

\subsection{iBioID Quantitative Analysis}

Following UPLC-MS/MS analyses, data was imported into Proteome Discoverer 2.2
(Thermo Scientific Inc.), and aligned based on the accurate mass and retention
time of detected ions (“features”) using Minora Feature Detector algorithm in
Proteome Discoverer. Relative peptide abundance was calculated based on
area-under-the-curve (AUC) of the selected ion chromatograms of the aligned
features across all runs. The MS/MS data was searched against the SwissProt Mus
musculus database (downloaded in April 2018) with additional proteins, including
yeast ADH1, bovine serum albumin, as well as an equal number of
reversed-sequence “decoys” for false discovery rate (FDR) determination. Mascot
Distiller and Mascot Server (v 2.5, Matrix Sciences) were utilized to produce
fragment ion spectra and to perform the database searches. Database search
parameters included fixed modification on Cys (carbamidomethyl), variable
modifications on Meth (oxidation) and Asn and Gln (deamidation), and were
searched at 5 ppm precursor and 0.02 Da product mass accuracy with full trypsin
enzymatic rules. Peptide Validator and Protein FDR Validator nodes in Proteome
Discoverer were used to annotate the data at a maximum 1\% protein FDR.

Protein intensities were exported from Proteome Discoverer and processed using
custom R scripts. Carboxylases and keratins, as well as 315 mitochondrial
proteins(Calvo et al., 2016), were removed from the identified proteins as known
contaminants.

Next, we performed sample loading normalization to account for
technical variation between the 9 individual MS runs. This is done by
multiplying intensities from each MS run by a scaling factor, such that the
average of all total run intensities are equal. As QC samples were created by
pooling equivalent aliquots of peptides from each biological replicate, the
average of all biological replicates should be equal to the average of all
technical SPQC replicates. We performed sample pool normalization to SPQC
samples to standardize protein measurements across all samples and correct for
batch effects between MS analyses. Sample pool normalization adjusts the
protein-wise mean of all biological replicates to be equal to the mean of all
SPQC replicates. Finally, proteins that were identified by a single peptide,
and/or identified in less than 50\% of samples were removed. Any remaining
missing values were inferred to be missing not at random due to the left shifted
distribution of proteins with missing values and imputed using the k-nearest
neighbors algorithm using the impute.knn function in the R package impute
(impute::impute.knn). Normalized protein data was analyzed using edgeR, an R
package for the analysis of differential expression/abundance that models count
data using a binomial distribution methodology. Differential enrichment of
proteins in the WASH1-BioID2 pull-down relative to the solubleBioID2 control
pull-down were evaluated with an exact test as implemented by the
edgeR::exactTest function. To consider a protein enriched in the WASH
interactome, we required that a protein exhibit a fold change greater than 3
over the negative control with an exact test Benjamini Hochberg adjusted p-value
(FDR) less than 0.1. With these criteria, 174 proteins were identified as WASH1
interactome proteins. Raw peptide and final normalized protein data as well as
the statistical results can be found in Table S1.

Proteins that function together often interact directly. We compiled
experimentally-determined protein-protein interactions (PPIs) among the WASH1
interactome from the HitPredict database(López et al., 2015) using a custom R
package, getPPIs, (available online at twesleyb/getPPIs). We report PPIs among
the WASH1 interactome in Table S1.

Bioinformatic GO analysis was conducted by manual annotation of identified
proteins and confirmed with Metascape analysis(Zhou et al., 2019) of
WASH1-BioID2 enriched proteins using the 2,311 proteins identified in the mass
spec analysis as background.

Raw peptide intensities were exported from Proteome Discover for downstream
analysis and processing in R. Following database searching, protein scoring
using the Protein FDR Validator algorithm, and removal of contaminant species,
the dataset retained 86,551 peptides corresponding to the identification of
7,488 unique proteins. These data, as well as statistical results can be found
in Table S2.

\subsection{TMT Proteomics Quantitative Analysis}

Peptide level data from the
spatial proteomics analysis of SWIP\textsuperscript{P1019R} MUT and MUT brain
were exported from Proteome Discoverer (version 2.4) and analyzed using custom R
and Python scripts.

Peptides from contaminant and non-mouse proteins were
removed. First, we performed sample loading normalization, normalizing the total
ion intensity for each TMT channel within an experiment to be equal. Sample
loading normalization corrects for small differences in the amount of sample
analyzed and labeling reaction efficiency differences between individual TMT
channels within an experiment.

We found that in each TMT experiment there were a small number of missing values
(mean percent missing = 1.6 +/- 0.17\%). Missing values were inferred to be
missing at random based on the overlapping distributions of peptides with
missing values and peptides without missing values. We imputed these missing
values using the k-nearest neighbor algorithm (impute::impute.knn). Missing
values for SPQC samples were not imputed. Peptides with any missing SPQC data
were removed.

Following sample loading normalization, SPQC replicates within each experiment
should yield identical measurements. As peptides with irreproducible QC
measurements are unlikely to be quantitatively robust, and their inclusion may
bias downstream processing (see IRS normalization below), we sought to remove
them. To assess intra-batch variability, we utilized the method described by
Ping et al., 2019(Ping et al., 2018). Briefly, peptides were binned into 5
groups based on the average intensity of the two SPQC replicates. For each pair
of SPQC measurements, the log ratio of SPQC intensities was calculated. To
identify outlier QC peptides, we plotted the distribution of these log ratios
for each bin. Peptides with ratios that were more than four standard deviations
away from the mean of its intensity bin were considered outliers and removed
(Total number of SPQC outlier peptides removed = 474).

Proteins were summarized as the sum of all unique peptide intensities
corresponding to a unique UniProtKB Accession identifier, and sample loading
normalization was performed across all three experiments to account for
inter-experimental technical variability. In a TMT experiment, the peptides
selected for MS2 fragmentation for any given protein is partially random,
especially at lower signal-to-noise peptides. This stochasticity means that
proteins are typically quantified by different peptides in each experiment.
Thus, although SPQC samples should yield identical protein measurements in each
of the three experiments (as it is the same sample analyzed in each experiment),
the observed protein measurements exhibit variability due to their
quantification by different peptides. To account for this protein-level bias, we
utilized the internal reference scaling (IRS) approach described by Plubell et
al., 2017(Plubell et al., 2017). IRS normalization scales the protein-wise
geometric average of all SPQC measurements across all experiments to be equal,
and simultaneously adjusts biological replicates. In brief, each protein is
multiplied by a scaling factor which adjusts its intra-experimental SPQC values
to be equal to the geometric mean of all SPQC values for the three experiments.
This normalization step effectively standardizes protein measurements between
different mass spectrometry experiments.

The final normalization step was to perform sample pool normalization using SPQC
samples as a reference. This normalization step, sometimes referred to as global
internal standard normalization, accounts for batch effects between experiments,
and reflects the fact that after technical normalization, the mean of biological
replicates should be equal to the mean of SPQC replicates.

Before assessing protein differential abundance, we removed irreproducible
proteins. This included proteins that were quantified in less than 50\% of all
samples, proteins that were identified by a single peptide, and proteins that
had missing SPQC values.

Across all 42 biological replicates, we observed that
a small number of proteins had potential outlier measurements that were either
several orders of magnitude greater or less than the mean of its replicates. In
order to identify and remove these proteins, we assessed the reproducibility of
protein measurements within a fraction in the same manner used to identify and
filter SPQC outlier peptides. A small number of proteins were identified as
outliers if the average log ratio of their 3 technical replicates was more than
4 standard deviations away from the mean of its intensity bin (n=349). In total,
we retained 5,897 of the original 7,488 proteins in the final dataset.

Differential protein abundance was assessed using the final normalized protein
data for intrafraction comparisons between WT and MUT groups using a general
linear model as implemented by the edgeR::glmQLFit and edgeR::glmQLFTest
functions(MD et al., 2009). Although this approach was originally devised for
analysis of single-cell RNA-sequencing data, this approach is also appropriate
for proteomics count data which is over-dispersed, negative binomially
distributed, and often only includes a small number of replicates (for an
example of edgeR's application to proteomics see Plubell et al., 2017(Plubell et
al., 2017))(McCarthy et al., 2012; MD et al., 2009). For intrafraction
comparisons, P-values were corrected using the Benjamini Hochberg procedure
within edgeR. An FDR threshold of 0.1 was set for significance for intrafraction
comparisons.

We utilized edgeR's flexible GLM framework to test the hypothesis that the
abundance of proteins in the WT group was significantly different from that in
the MUT group irrespective of fraction differences (Table S2). For WT vs. MUT
contrasts, we considered proteins with an FDR < 0.05 significant (n=687). For
plotting, we adjusted normalized protein abundances for fraction differences by
fitting the data with an additive linear model with fraction as a blocking
factor, as implemented by the removeBatchEffect algorithm from the R limma
package(Ritchie et al., 2015).

To construct a protein covariation graph, we assessed the pairwise covariation
(correlation) between all 5,897 proteins using the biweight midcorrelation
(WGCNA::bicor) statistic(Seyfried et al., 2017), a robust alternative to
Pearson's correlation. The resulting complete, signed, weighted, and symmetric
adjacency matrix was then re-weighted using the 'Network Enhancement' approach.
Network enhancement removes noise from the graph, and facilitates downstream
community detection(Wang et al., 2018).

The enhanced adjacency matrix was clustered using the Leiden algorithm(Traag et
al., 2019), a recent extension and improvement of the well-known Louvain
algorithm(Mucha et al., 2010). The Leiden algorithm functions to optimize the
partition of a graph into modules by maximizing a quality statistic. We utilized
the 'Surprise' quality statistic(Traag et al., 2015) to identify optimal
partitions of the protein covariation graph. To facilitate biological inferences
drawn from the network's organization, we recursively split 27 modules that
contained more than 100 nodes and removed modules that were smaller than 5
proteins. Initial clustering of the network resulted in the identification of
324 modules.

To reduce the likelihood of identifying false positive modules, we enforced
module quality using a permutation procedure
(NetRep::modulePreservation)(Ritchie et al., 2016) and removed modules with any
insignificant permutation statistics (Bonferroni P-Adjust > 0.05). The following
statistics were used to enforce module quality: 'avg.weight' (average edge
weight), 'avg.cor' (average bicor correlation R2), and 'avg.contrib' (quantifies
how similar an individual protein's abundance profile is to the summary of its
module). Proteins which were assigned to modules with insignificant module
quality statistics were not considered clustered as the observed quality of
their module does not differ from random.

After filtering, approximately 85\%
of all proteins were assigned a cluster. The median percent variance explained
by the first principle component of a module (a measure of module cohesiveness)
was high (59.8\%). After removal of low-quality modules, the analysis retained
255 distinct modules of proteins that strongly covaried together (Table S3).

To evaluate modules that were changing between WT and MUT genotypes, we extended
the GLM framework to test for protein differential abundance. Modules were
summarized as the sum of their proteins and fit with a GLM, with fraction as a
blocking factor. In this statistical design, we were interested in the average
effect of genotype on all proteins in a module. For plotting, module abundance
was adjusted for fraction differences using the removeBatchEffect function
(package: limma).

We utilized the Bonferroni method to adjust P-values for 255 module level
comparisons and considered modules with an adjusted P-value less than 0.05 were
considered significant (n=37).

\subsection{Module Gene Set Enrichment Analysis}
Modules were analyzed for enrichment of the WASH interactome (this paper), Retriever complex (McNally et al., 2017), CORUM
protein complexes (Giurgiu et al., 2019), and subcellular predictions generated
by Geladaki et al.(Geladaki et al., 2019) using the hypergeometric test with
Bonferroni P-value correction for multiple comparisons.

The union of all
clustered and pathway proteins was used as background for the hypergeometric
test. In addition to analysis of these general cellular pathways, we analyzed
modules for enrichment of neuron-specific subcellular compartments—this included
the presynapse (Takamori et al., 2006), excitatory postsynapse (Uezu et al.,
2016), and inhibitory postsynapse (Uezu et al., 2016). These gene lists are
available online at https://github.com/twesleyb/geneLists.

\subsection{Network Visualization}
Network graphs were visualized in Cytoscape (Version 3.7.2). We
used the Perfuse Force Directed Layout (weight = edge weight). In this layout,
strongly connected nodes tend to be positioned closer together. In some
instances, node location was manually adjusted to visualize the module more
compactly. Node size was set to be proportional to the weighted degree
centrality of a node in its module subgraph. Node size thus reflects node
importance in the module. Visualizing co-expression or co-variation networks is
challenging because every node is connected to every other node (the graph is
complete). To aid visualization of module topology, we removed weak edges from
the graphs. A threshold for each module was set to remove the maximal number of
edges before the module subgraph split into multiple components. This strategy
enables visualization of the strongest paths in a network.
